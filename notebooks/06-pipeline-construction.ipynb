{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m train\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m augmentation \u001b[38;5;28;01mas\u001b[39;00m aug\n\u001b[1;32m     10\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/dividend-cut-predictor/src/modelling/training.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score, classification_report\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/projects/dividend-cut-predictor/src/modelling/models.py:84\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, params):\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLogisticWrapper\u001b[39;00m(WrappedModel):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, solver, n_jobs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m=\u001b[39m solver\n",
      "File \u001b[0;32m~/projects/dividend-cut-predictor/src/modelling/models.py:96\u001b[0m, in \u001b[0;36mLogisticWrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstant_params \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtuned_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, X, y, transform_pipeline:\u001b[43msklearn\u001b[49m\u001b[38;5;241m.\u001b[39mp):\n\u001b[1;32m     97\u001b[0m     C \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m10\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     98\u001b[0m     penalty \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenalty\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import configparser\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "from src.utils import utils\n",
    "from src.modelling import training as train\n",
    "from src.data_processing import augmentation as aug\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def main(model_name:str, tune_trials=10, balance_data=False):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    proj_root = utils.get_proj_root()\n",
    "\n",
    "    config = configparser.ConfigParser(interpolation=None)\n",
    "    config.read(proj_root.joinpath('config/data_config.ini'))\n",
    "\n",
    "    final_year = int(config['year_limits']['end_year'])\n",
    "\n",
    "    training_data_rel_path = config['data_paths']['preprocessed_data_path']\n",
    "    training_data_path =  proj_root.joinpath(training_data_rel_path)\n",
    "    feature_set_path = proj_root.joinpath(config['modelling_paths']['optimal_features'])\n",
    "    model_output_dir = proj_root.joinpath(config['modelling_paths']['model_output'])\n",
    "\n",
    "    label_col_name = 'dps_change_next_year'\n",
    "    optimal_features = train.get_features(feature_set_path) \n",
    "\n",
    "    model_params = config._sections[model_name]\n",
    "    \n",
    "    model_class = train.get_model_class(model_name=model_name)\n",
    "    model = model_class(**model_params)\n",
    "\n",
    "    # get data\n",
    "    training_data = train.get_training_data(file_path=training_data_path)\n",
    "\n",
    "    # split dataset\n",
    "    training_data_subset, testing_data_subset = train.train_test_split(df=training_data, final_year=final_year)\n",
    "\n",
    "    if balance_data:\n",
    "    # balance data\n",
    "        training_data_subset = aug.balance_data(training_data_subset, label_col_name=label_col_name)\n",
    "\n",
    "    training_data_subset = training_data_subset[optimal_features+[label_col_name]]\n",
    "    testing_data_subset = testing_data_subset[optimal_features+[label_col_name]]\n",
    "\n",
    "    model_output_path = model_output_dir.joinpath(model_name+'.pkl')\n",
    "    trainer = train.ModelTrainer(model_class=model,\n",
    "                                    training_data=training_data_subset,\n",
    "                                    testing_data=testing_data_subset,\n",
    "                                    label_col_name=label_col_name,\n",
    "                                    model_output_path=model_output_path)\n",
    "\n",
    "    print('tuning model')\n",
    "    trainer.tune_model(n_trials=tune_trials)\n",
    "    logger.info('tuning completed')\n",
    "    model = trainer.train_model(save_model=True)\n",
    "    logger.info('training completed')\n",
    "\n",
    "    score = trainer.evaluate_model(show_report=True)\n",
    "    logger.info(f'test score:{score}')\n",
    "    print(training_data_subset.columns)\n",
    "    print(testing_data_subset.columns)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_fmt)\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='training model')\n",
    "    parser.add_argument(\"--model_name\", type=str)\n",
    "    parser.add_argument(\"--tune_trials\", type=int, default=1)\n",
    "    parser.add_argument(\"--balance_data\", action=argparse.BooleanOptionalAction)\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    args = parser.parse_args(['--model_name', 'random_forest', '--tune_trials', '1', '--balance_data'])\n",
    "\n",
    "    main(model_name=args.model_name,\n",
    "         tune_trials=args.tune_trials, balance_data=args.balance_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers.py\n",
    "\n",
    "\"\"\" List of functions for data processing. \"\"\"\n",
    "\n",
    "from typing import Literal, Sequence\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "class CollinearColsRemover(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, thresh, label_col) -> None:\n",
    "        self.thresh = thresh\n",
    "        self.label_col = label_col\n",
    "    \n",
    "    \n",
    "    def fit(self, X:pd.DataFrame, y=None):\n",
    "        X = X.copy()\n",
    "        X.drop(labels=self.label_col, axis=1, inplace=True)\n",
    "        self.cols_to_drop = self._get_collinear_cols(df=X, thresh=self.thresh)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X:pd.DataFrame):\n",
    "        n_cols = X.shape[1]\n",
    "        X = X.drop(self.cols_to_drop, axis=1)\n",
    "        new_n_cols = X.shape[1]\n",
    "        n_cols_dropped = n_cols - new_n_cols\n",
    "        # print(type(X))\n",
    "        logging.getLogger(self.__class__.__name__).info(f'dropped {n_cols_dropped} cols')\n",
    "        return X\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_collinear_cols(df:pd.DataFrame, thresh:np.float_):\n",
    "\n",
    "        df = df.select_dtypes(include=np.float_)\n",
    "\n",
    "        corr_mat = df.corr().abs()\n",
    "        corr_mat_u = corr_mat.where(np.triu(np.ones(corr_mat.shape), k=1)\n",
    "                                    .astype(np.bool_))\n",
    "\n",
    "        cols_to_drop = [col for col in corr_mat_u.columns \\\n",
    "                    if any(corr_mat_u[col] > thresh)]\n",
    "        \n",
    "        return cols_to_drop\n",
    "    \n",
    "\n",
    "class ColumnsOrdinalEncoder(OrdinalEncoder):\n",
    "\n",
    "\n",
    "    def __init__(self, col_names) -> None:\n",
    "        self.col_names = col_names\n",
    "        \n",
    "        super().__init__(dtype=int)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        data_subset = X[self.col_names]\n",
    "\n",
    "        return super().fit(X=data_subset)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        data_subset = X[self.col_names]\n",
    "        transformed_data = super().transform(data_subset)\n",
    "\n",
    "        X[self.col_names] = transformed_data\n",
    "\n",
    "        return X\n",
    "    \n",
    "class  OptimalColumnSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, n_min_cols=2, optimal_cols_path=None) -> None:\n",
    "        super().__init__()\n",
    "        self.n_min_cols = n_min_cols\n",
    "        self.optimal_cols_path = optimal_cols_path\n",
    "        self.cols_to_drop = None\n",
    "\n",
    "    def fit(self, X:pd.DataFrame, y=None):\n",
    "        if self.optimal_cols_path is not None:\n",
    "            try:\n",
    "                optimal_col_names = utils.load_value(self.optimal_cols_path)\n",
    "            except(FileNotFoundError):\n",
    "                raise FileNotFoundError('File for optimal columns not available \\\n",
    "                                        optimal columns should be determined first.')\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X:pd.DataFrame):\n",
    "\n",
    "        X = X.drop(self.cols_to_drop, axis=1)\n",
    "\n",
    "        logging.getLogger(self.__class__.__name__).info(f'selected columns: {self.cols_to_drop}')\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.py\n",
    "\"\"\"Scripts for constituting models\"\"\"\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import optuna\n",
    "from abc import ABC, abstractmethod\n",
    "import configparser\n",
    "import logging\n",
    "\n",
    "from src.utils import utils\n",
    "\n",
    "\n",
    "\n",
    "class WrappedModel(ABC):\n",
    "    @abstractmethod\n",
    "    def train(self, X_train, y_train, transform_pipeline:Pipeline=None):\n",
    "        \"\"\"\n",
    "        Train the model on the given training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train: Input features for training.\n",
    "        - y_train: Target labels for training.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using the trained model.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input features for prediction.\n",
    "\n",
    "        Returns:\n",
    "        - Predicted labels.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def objective_function(self, trial, X, y, transform_pipeline:Pipeline=None):\n",
    "        \"\"\"\n",
    "        Objective function for optimization tasks.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input features for objective evaluation.\n",
    "        - y: Target labels for objective evaluation.\n",
    "\n",
    "        Returns:\n",
    "        - Objective value (e.g., accuracy, loss).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def init_model(self, params):\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "class LogisticWrapper(WrappedModel):\n",
    "    \n",
    "    def __init__(self, solver, n_jobs) -> None:\n",
    "        self.solver = solver\n",
    "        self.n_jobs=int(n_jobs)\n",
    "        self.model = LogisticRegression\n",
    "        self.is_tuned=False\n",
    "        self.tunable_params =('C', 'penalty')\n",
    "        self.constant_params = ('solver', 'n_jobs')\n",
    "        self.tuned_params=None\n",
    "\n",
    "\n",
    "    def objective_function(self, trial, X, y, transform_pipeline:Pipeline):\n",
    "        C = trial.suggest_float('C', 0.1, 10, log=True)\n",
    "        penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "\n",
    "        model = self.model(\n",
    "            C=C,\n",
    "            penalty=penalty,\n",
    "            solver=self.solver,\n",
    "            n_jobs=self.n_jobs\n",
    "        )\n",
    "\n",
    "        if transform_pipeline is not None:\n",
    "            model = transform_pipeline.steps.append(['logistic-regressor-model', model])\n",
    "        # Using cross_val_score to get the average precision score for each fold\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')\n",
    "        roc_auc = np.mean(scores)\n",
    "        # Printing intermediate results\n",
    "        print(f\"Trial {trial.number}, C: {C}, penalty: {penalty}, ROC-AUC: {roc_auc}\")\n",
    "        return roc_auc\n",
    "    \n",
    "    def init_model(self):\n",
    "\n",
    "        if self.tuned_params is not None:\n",
    "            print('using tuned params')\n",
    "            model = self.model(**self.tuned_params, \n",
    "                               solver=self.solver, n_jobs=self.n_jobs)\n",
    "        else:\n",
    "            print(\"not using tuned\")\n",
    "            model = self.model(solver=self.solver, n_jobs=self.n_jobs)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        \n",
    "    def train(self, X, y, transform_pipeline:Pipeline=None):\n",
    "\n",
    "        if not self.is_tuned:\n",
    "            self.init_model()\n",
    "\n",
    "        logging.getLogger(self.__class__.__name__).info(f'training with {type(self.model)}')\n",
    "\n",
    "        if transform_pipeline is not None:\n",
    "            pipeline_w_model = transform_pipeline.steps.append(['logistic model', self.model])\n",
    "            model = pipeline_w_model.fit(X, y)\n",
    "        else:\n",
    "            model = self.model.fit(X, y)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def predict(self, X, return_prob=False):\n",
    "        if return_prob:\n",
    "            y_pred = self.model.predict_proba(X)[:, 1]\n",
    "        else:\n",
    "            y_pred = self.model.predict(X)\n",
    "        return y_pred\n",
    "\n",
    "    \n",
    "class RandomForestWrapper(WrappedModel):\n",
    "    \n",
    "    def __init__(self, n_jobs) -> None:\n",
    "        self.n_jobs=int(n_jobs)\n",
    "        self.model = RandomForestClassifier\n",
    "        self.is_tuned=False\n",
    "        self.tuned_params=None\n",
    "\n",
    "\n",
    "    def objective_function(self, trial, X, y):\n",
    "        n_estimators = trial.suggest_int('n_estimators', 2, 150)\n",
    "        max_depth = trial.suggest_int('max_depth', 1, 50)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 15)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 15)\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Using cross_val_score to get the average ROC-AUC score for each fold\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')\n",
    "        roc_auc = np.mean(scores)\n",
    "        # Printing intermediate results\n",
    "        print(f\"Trial {trial.number}, n_estimators: {n_estimators}, max_depth: {max_depth}, \"\n",
    "            f\"min_samples_split: {min_samples_split}, min_samples_leaf: {min_samples_leaf}, ROC-AUC: {roc_auc}\")\n",
    "        return roc_auc\n",
    "\n",
    "    def init_model(self):\n",
    "\n",
    "        if self.tuned_params is not None:\n",
    "            model = self.model(**self.tuned_params, \n",
    "                                n_jobs=self.n_jobs)\n",
    "        else:\n",
    "            model = self.model(n_jobs=self.n_jobs)\n",
    "\n",
    "        self.model = model\n",
    "        \n",
    "    def train(self, X, y):\n",
    "\n",
    "        if not self.is_tuned:\n",
    "            self.init_model()\n",
    "\n",
    "        print(type(self.model))\n",
    "        self.model.fit(X, y)\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, X, return_prob=False):\n",
    "        if return_prob:\n",
    "            y_pred = self.model.predict_proba(X)[:, 1]\n",
    "        else:\n",
    "            y_pred = self.model.predict(X)\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traini.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training.py\n",
    "\n",
    "\"\"\"utilities for training model with training data\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import logging\n",
    "import pathlib\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import sklearn\n",
    "from src.modelling import models\n",
    "\n",
    "\n",
    "from src.utils import utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ModelTrainer():\n",
    "\n",
    "    def __init__(self, model_class:models.WrappedModel, transform_pipeline,\n",
    "                 training_data, testing_data, label_col_name, model_output_path, \n",
    "                 balance_data:bool=True, n_trials:int=100) -> None:\n",
    "\n",
    "        # self.direction=None\n",
    "        self.best_params = None\n",
    "        self.model_output_path = model_output_path\n",
    "        self.model_class = model_class\n",
    "        self.n_trials = n_trials\n",
    "        self.tune_best_score = None\n",
    "        self.training_data = training_data\n",
    "        self.testing_data = testing_data\n",
    "        self.label_col_name = label_col_name\n",
    "        self.transform_pipeline = transform_pipeline\n",
    "        self.trained_model=None\n",
    "\n",
    "        if balance_data:\n",
    "            self.training_data = aug.balance_data(df=self.training_data, label_col_name=self.label_col_name)\n",
    "\n",
    "    def get_optimal_features():\n",
    "        pass\n",
    "\n",
    "\n",
    "    def tune_model(self, n_trials, maximize=True):\n",
    "        \n",
    "        if maximize:\n",
    "            direction='maximize'\n",
    "        else:\n",
    "            direction = 'minimize'\n",
    "        self.direction=direction\n",
    "\n",
    "        X_train, y_train = split_Xy(self.training_data, label_col_name=self.label_col_name)\n",
    "\n",
    "        \n",
    "\n",
    "        study = optuna.create_study(direction=direction)\n",
    "        study.optimize(lambda trial: self.model_class.objective_function(\n",
    "            trial=trial, X=X_train, y=y_train),\n",
    "            n_trials=n_trials, transform_pipeline=self.transform_pipeline\n",
    "        )\n",
    "\n",
    "        self.best_params = study.best_params\n",
    "        self.tune_best_score = study.best_value\n",
    "        self.model_class.tuned_params = study.best_params\n",
    "        # model = self.model_class.init_model(params=self.best_params)\n",
    "        self.model_class.init_model()\n",
    "        # self.model_class.model = model\n",
    "        self.model_class.is_tuned=True\n",
    "        print(f'best score is: {self.best_score}')\n",
    "\n",
    "    def train_model(self,  save_model=True) -> Pipeline:\n",
    "\n",
    "        X_train, y_train = split_Xy(self.training_data, label_col_name=self.label_col_name)\n",
    "\n",
    "        model_is_tuned = self.model_class.is_tuned\n",
    "        if not model_is_tuned:\n",
    "            logging.getLogger(self.__class__.__name__).info('model is not tuned')\n",
    "\n",
    "        trained_model = self.model_class.train(X=X_train, y=y_train, transform_pipeline=self.transform_pipeline)\n",
    "\n",
    "        if save_model:\n",
    "            utils.save_value(trained_model, fname=self.model_output_path)\n",
    "\n",
    "        self.trained_model = trained_model\n",
    "\n",
    "        return trained_model\n",
    "    \n",
    "    def evaluate_model(self, show_report=True):\n",
    "        \n",
    "        X_test, y_test = split_Xy(self.testing_data, label_col_name=self.label_col_name)\n",
    "\n",
    "        y_pred_prob = self.trained_model.predict_proba(X_test)\n",
    "        y_pred = self.trained_model.predict(X_test)\n",
    "        score = roc_auc_score(y_true=y_test, y_score=y_pred_prob)\n",
    "\n",
    "        if show_report:\n",
    "            print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "        return score    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def get_features(path:pathlib.Path):\n",
    "\n",
    "    features_list = utils.load_value(path)\n",
    "\n",
    "    return features_list\n",
    "\n",
    "\n",
    "def get_training_data(file_path:pathlib.Path=None):\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_test_split(df:pd.DataFrame, final_year:int, save_data=False):\n",
    "\n",
    "    # final_year = int(config['year_limits']['end_year'])\n",
    "\n",
    "    training_data = df.loc[df['year'] != final_year]\n",
    "    testing_data = df.loc[df['year'] == final_year]\n",
    "\n",
    "    logger.info(f\"data split into: training ({training_data.shape}) and test ({testing_data.shape}) sets \")\n",
    "\n",
    "\n",
    "    return training_data, testing_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_Xy(df:pd.DataFrame, label_col_name:str):\n",
    "\n",
    "    X = df.drop(label_col_name, axis=1)\n",
    "    y = df[label_col_name]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def get_model_class(model_name:str):\n",
    "    if model_name == 'logistic_regression':\n",
    "        model = models.LogisticWrapper\n",
    "    elif model_name == 'random_forest':\n",
    "        model = models.RandomForestWrapper\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def save_data(data:pd.DataFrame, path:pathlib.Path):\n",
    "\n",
    "    data.to_csv(path_or_buf=path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training main\n",
    "\n",
    "import logging\n",
    "import configparser\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "from src.utils import utils\n",
    "from src.modelling import training as train\n",
    "from src.data_processing import augmentation as aug\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def main(model_name:str, tune_trials=10, balance_data=False):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    proj_root = utils.get_proj_root()\n",
    "\n",
    "    config = configparser.ConfigParser(interpolation=None)\n",
    "    config.read(proj_root.joinpath('config/data_config.ini'))\n",
    "\n",
    "    final_year = int(config['year_limits']['end_year'])\n",
    "\n",
    "    training_data_rel_path = config['data_paths']['preprocessed_data_path']\n",
    "    training_data_path =  proj_root.joinpath(training_data_rel_path)\n",
    "    feature_set_path = proj_root.joinpath(config['modelling_paths']['optimal_features'])\n",
    "    model_output_dir = proj_root.joinpath(config['modelling_paths']['model_output'])\n",
    "\n",
    "    label_col_name = 'dps_change_next_year'\n",
    "    optimal_features = train.get_features(feature_set_path) \n",
    "\n",
    "    model_params = config._sections[model_name]\n",
    "    \n",
    "    model_class = train.get_model_class(model_name=model_name)\n",
    "    model = model_class(**model_params)\n",
    "\n",
    "    # get data\n",
    "    training_data = train.get_training_data(file_path=training_data_path)\n",
    "\n",
    "    # split dataset\n",
    "    training_data_subset, testing_data_subset = train.train_test_split(df=training_data, final_year=final_year)\n",
    "\n",
    "    if balance_data:\n",
    "    # balance data\n",
    "        training_data_subset = aug.balance_data(training_data_subset, label_col_name=label_col_name)\n",
    "\n",
    "    training_data_subset = training_data_subset[optimal_features+[label_col_name]]\n",
    "    testing_data_subset = testing_data_subset[optimal_features+[label_col_name]]\n",
    "\n",
    "    model_output_path = model_output_dir.joinpath(model_name+'.pkl')\n",
    "    trainer = train.ModelTrainer(model_class=model,\n",
    "                                    training_data=training_data_subset,\n",
    "                                    testing_data=testing_data_subset,\n",
    "                                    label_col_name=label_col_name,\n",
    "                                    model_output_path=model_output_path)\n",
    "\n",
    "    logger.info('==========tuning model============')\n",
    "    trainer.tune_model(n_trials=tune_trials)\n",
    "    logger.info('========training model============')\n",
    "    model = trainer.train_model(save_model=True)\n",
    "    logger.info('training completed')\n",
    "\n",
    "    score = trainer.evaluate_model(show_report=True)\n",
    "    logger.info(f'test score:{score}')\n",
    "    print(training_data_subset.columns)\n",
    "    print(testing_data_subset.columns)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_fmt)\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='training model')\n",
    "    parser.add_argument(\"--model_name\", type=str)\n",
    "    parser.add_argument(\"--tune_trials\", type=int, default=1)\n",
    "    parser.add_argument(\"--balance_data\", action=argparse.BooleanOptionalAction)\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    args = parser.parse_args(['--model_name', 'random_forest', '--tune_trials', '1', '--balance_data'])\n",
    "\n",
    "    main(model_name=args.model_name,\n",
    "         tune_trials=args.tune_trials, balance_data=args.balance_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.modelling import transforms\n",
    "\n",
    "proj_root = utils.get_proj_root()\n",
    "\n",
    "config = configparser.ConfigParser(interpolation=None)\n",
    "config.read(proj_root.joinpath('config/data_config.ini'))\n",
    "\n",
    "feature_set_path = proj_root.joinpath(config['modelling_paths']['optimal_features'])\n",
    "label_col_name = 'dps_change_next_year'\n",
    "categorical_features = ['industry', 'symbol']\n",
    "collinear_thresh = 0.98\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('remove collinear columns', transforms.CollinearColsRemover(thresh=collinear_thresh, \n",
    "                                                                    label_col=label_col_name)),\n",
    "    ('cat_to_ordinal_cols', transforms.ColumnsOrdinalEncoder(col_names=categorical_features)),\n",
    "    ('select optimal cols', transforms.OptimalColumnSelector(optimal_cols_path=feature_set_path))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('select optimal cols',\n",
       " OptimalColumnSelector(optimal_cols_path=PosixPath('/home/aroge/projects/dividend-cut-predictor/models/artifacts/optimal_features.pkl')))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "[('remove collinear columns', CollinearColsRemover(label_col='dps_change_next_year', thresh=0.98)), ('cat_to_ordinal_cols', ColumnsOrdinalEncoder(col_names=['industry', 'symbol'])), ('select optimal cols', OptimalColumnSelector(optimal_cols_path=PosixPath('/home/aroge/projects/dividend-cut-predictor/models/artifacts/optimal_features.pkl'))), LogisticRegression()]\n",
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "m = sklearn.clone(pipeline)\n",
    "m.steps.append(sklearn.linear_model.LogisticRegression())\n",
    "print(type(m))\n",
    "print(m.steps)\n",
    "print(m.steps[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;remove collinear columns&#x27;,\n",
       "                 CollinearColsRemover(label_col=&#x27;dps_change_next_year&#x27;,\n",
       "                                      thresh=0.98)),\n",
       "                (&#x27;cat_to_ordinal_cols&#x27;,\n",
       "                 ColumnsOrdinalEncoder(col_names=[&#x27;industry&#x27;, &#x27;symbol&#x27;])),\n",
       "                (&#x27;select optimal cols&#x27;,\n",
       "                 OptimalColumnSelector(optimal_cols_path=PosixPath(&#x27;/home/aroge/projects/dividend-cut-predictor/models/artifacts/optimal_features.pkl&#x27;))),\n",
       "                &lt;Recursion on Pipeline with id=140270721063072&gt;,\n",
       "                &lt;Recursion on Pipeline with id=140270721063072&gt;,\n",
       "                &lt;Recursion on Pipeline with id=140270721063072&gt;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;remove collinear columns&#x27;,\n",
       "                 CollinearColsRemover(label_col=&#x27;dps_change_next_year&#x27;,\n",
       "                                      thresh=0.98)),\n",
       "                (&#x27;cat_to_ordinal_cols&#x27;,\n",
       "                 ColumnsOrdinalEncoder(col_names=[&#x27;industry&#x27;, &#x27;symbol&#x27;])),\n",
       "                (&#x27;select optimal cols&#x27;,\n",
       "                 OptimalColumnSelector(optimal_cols_path=PosixPath(&#x27;/home/aroge/projects/dividend-cut-predictor/models/artifacts/optimal_features.pkl&#x27;))),\n",
       "                &lt;Recursion on Pipeline with id=140270721063072&gt;,\n",
       "                &lt;Recursion on Pipeline with id=140270721063072&gt;,\n",
       "                &lt;Recursion on Pipeline with id=140270721063072&gt;])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('remove collinear columns',\n",
       "                 CollinearColsRemover(label_col='dps_change_next_year',\n",
       "                                      thresh=0.98)),\n",
       "                ('cat_to_ordinal_cols',\n",
       "                 ColumnsOrdinalEncoder(col_names=['industry', 'symbol'])),\n",
       "                ('select optimal cols',\n",
       "                 OptimalColumnSelector(optimal_cols_path=PosixPath('/home/aroge/projects/dividend-cut-predictor/models/artifacts/optimal_features.pkl'))),\n",
       "                <Recursion on Pipeline with id=140270721063072>,\n",
       "                <Recursion on Pipeline with id=140270721063072>,\n",
       "                <Recursion on Pipeline with id=140270721063072>])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline = pipeline.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;remove collinear columns&#x27;,\n",
       "                 CollinearColsRemover(label_col=&#x27;dps_change_next_year&#x27;,\n",
       "                                      thresh=0.98)),\n",
       "                (&#x27;cat_to_ordinal_cols&#x27;,\n",
       "                 ColumnsOrdinalEncoder(col_names=[&#x27;industry&#x27;, &#x27;symbol&#x27;])),\n",
       "                (&#x27;select optimal cols&#x27;,\n",
       "                 OptimalColumnSelector(optimal_cols_path=PosixPath(&#x27;/home/aroge/projects/dividend-cut-predictor/models/artifacts/optimal_features.pkl&#x27;))),\n",
       "                &lt;Recursion on Pipeline with id=140270721063072&gt;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;remove collinear columns&#x27;,\n",
       "                 CollinearColsRemover(label_col=&#x27;dps_change_next_year&#x27;,\n",
       "                                      thresh=0.98)),\n",
       "                (&#x27;cat_to_ordinal_cols&#x27;,\n",
       "                 ColumnsOrdinalEncoder(col_names=[&#x27;industry&#x27;, &#x27;symbol&#x27;])),\n",
       "                (&#x27;select optimal cols&#x27;,\n",
       "                 OptimalColumnSelector(optimal_cols_path=PosixPath(&#x27;/home/aroge/projects/dividend-cut-predictor/models/artifacts/optimal_features.pkl&#x27;))),\n",
       "                &lt;Recursion on Pipeline with id=140270721063072&gt;])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('remove collinear columns',\n",
       "                 CollinearColsRemover(label_col='dps_change_next_year',\n",
       "                                      thresh=0.98)),\n",
       "                ('cat_to_ordinal_cols',\n",
       "                 ColumnsOrdinalEncoder(col_names=['industry', 'symbol'])),\n",
       "                ('select optimal cols',\n",
       "                 OptimalColumnSelector(optimal_cols_path=PosixPath('/home/aroge/projects/dividend-cut-predictor/models/artifacts/optimal_features.pkl'))),\n",
       "                <Recursion on Pipeline with id=140270721063072>])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
